{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import urllib.request\n",
    "import dateutil.parser\n",
    "import dateutil.rrule\n",
    "import dateutil.tz\n",
    "import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import matplotlib.patheffects as pe\n",
    "import re\n",
    "\n",
    "# Plotting is externalised\n",
    "import importlib\n",
    "import traffic\n",
    "\n",
    "importlib.reload(traffic)\n",
    "\n",
    "# Used across most of the plots for people flows\n",
    "tzLocal = dateutil.tz.gettz('Europe/London')\n",
    "dateToday = datetime.datetime.combine(datetime.date.today(), datetime.datetime.min.time()).replace(tzinfo=tzLocal)\n",
    "plottableTypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "peakHours = [7, 8, 9, 16, 17, 18]\n",
    "interPeakHours = [10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# Amount of 15 minute time slots allowed to be missing\n",
    "capMissingAllHours = 3600 * 2.5 # No more than 2.5 hours missing\n",
    "\n",
    "capMissingSubHours = 1800 # No more than 30 minutes missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlaceAverages = None\n",
    "dfAllSeries = {}\n",
    "\n",
    "def addAverage(placeName, average):\n",
    "    global dfPlaceAverages\n",
    "    \n",
    "    average = average.to_frame(name=placeName)\n",
    "    \n",
    "    if dfPlaceAverages is None:\n",
    "        dfPlaceAverages = average\n",
    "    else:\n",
    "        if placeName in dfPlaceAverages.columns:\n",
    "            dfPlaceAverages.drop(columns=[placeName], inplace=True)\n",
    "        dfPlaceAverages = dfPlaceAverages.join(\n",
    "            average, \n",
    "            how='outer'\n",
    "        )\n",
    "        \n",
    "def addSeries(placeName, frame, period = 'all'):\n",
    "    global dfAllSeries\n",
    "    \n",
    "    if period not in dfAllSeries:\n",
    "        dfAllSeries[period] = None\n",
    "    \n",
    "    if dfAllSeries[period] is None:\n",
    "        dfAllSeries[period] = frame.copy()\n",
    "    else:\n",
    "        dfAllSeries[period] = dfAllSeries[period].join(\n",
    "            frame, \n",
    "            how='outer',\n",
    "            lsuffix=placeName\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic volumes against a baseline\n",
    "\n",
    "In the Downing Street daily press briefings during coronavirus, a series of slides are presented indicating the change in motor vehicle traffic, relative to a baseline. The [methodology is described in this document](https://www.gov.uk/government/publications/coronavirus-covid-19-transport-data-methodology-note), and [the slides are available on GOV.UK](https://www.gov.uk/government/collections/slides-and-datasets-to-accompany-coronavirus-press-conferences).\n",
    "\n",
    "The charts shown below are intentionally presented in a similar style, but for smaller geographies and with specific measurements highlighted that could be indicators for the purpose of the journeys, such as those near to supermarkets, hospitals, connecting to the strategic road network, or near industrial complexes. \n",
    "\n",
    "You can [download the calculated percentages as a CSV file](https://covid.view.urbanobservatory.ac.uk/output/all-traffic-relative.csv).\n",
    "\n",
    "### Tyne and Wear\n",
    "\n",
    "This region's statistics are obtained from aggregate statistics collected by automatic numberplate recognition cameras (ANPR), used to invoke signal and traffic control strategies in the region. The underlying ANPR data is aggregated to four minute intervals. The data is provided by [Tyne and Wear UTMC](https://www.transportnortheast.com/public/map/map.htm) and archived by the [Newcastle Urban Observatory](http://www.urbanobservatory.ac.uk/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#govChartStart = datetime.datetime.strptime('2020-03-01T00:00:00Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzLocal)\n",
    "#dateBaselineEnd = datetime.datetime.strptime('2020-03-15T23:59:59Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzLocal)\n",
    "#trafficCountInterval = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTrafficTyneWear = pickle.load(open('../cache/recent-traffic-volumes-pd.pkl', 'rb'))\n",
    "\n",
    "# TODO: Make this reflect the last entry in the frame, not the time now\n",
    "print('Last data obtained %s' \n",
    "    % (np.max(pdTrafficTyneWear.index).strftime('%d %B %Y %H:%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExE5Ulih1KDJ"
   },
   "outputs": [],
   "source": [
    "skipStart = datetime.datetime.strptime('2020-03-17T00:00:00Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzLocal)\n",
    "skipEnd = datetime.datetime.strptime('2020-03-18T23:59:59Z', '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=tzLocal)\n",
    "\n",
    "# Points have already been de-duplicated in the update script. Only unique easting/northing pairs are included\n",
    "pdTrafficTyneWear = pdTrafficTyneWear[(pdTrafficTyneWear.index < skipStart) | (pdTrafficTyneWear.index > skipEnd)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExE5Ulih1KDJ"
   },
   "outputs": [],
   "source": [
    "pdTrafficRecentRelativePc = traffic.makeRelativeToBaseline(pdTrafficTyneWear, capMissingAllHours)\n",
    "\n",
    "pdTrafficRecentRelativePcPeak = traffic.makeRelativeToBaseline(pdTrafficTyneWear, capMissingSubHours, peakHours)\n",
    "pdTrafficRecentRelativePcInterPeak = traffic.makeRelativeToBaseline(pdTrafficTyneWear, capMissingSubHours, interPeakHours)\n",
    "# pdTrafficRecentRelativePc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyneWearAuthorities = {\n",
    "    'GH': 'Gateshead',\n",
    "    'NB': 'Northumberland',\n",
    "    'NC': 'Newcastle upon Tyne',\n",
    "    'NT': 'North Tyneside',\n",
    "    'SL': 'Sunderland',\n",
    "    'ST': 'South Tyneside',\n",
    "    'CD': 'County Durham'\n",
    "}\n",
    "tyneWearSensorZones = {}\n",
    "\n",
    "for sensor in pdTrafficRecentRelativePc.columns:\n",
    "    m = re.search('^CAJT_([A-Z]{2})', sensor)\n",
    "    if m is None:\n",
    "        # County Durham...\n",
    "        if sensor.startswith('ANPR'):    \n",
    "            authority = 'CD'\n",
    "        else:\n",
    "            authority = 'Unknown'\n",
    "    else:\n",
    "        authority = m.group(1)\n",
    "        \n",
    "    if (authority not in tyneWearSensorZones):\n",
    "        tyneWearSensorZones[authority] = []\n",
    "    tyneWearSensorZones[authority].append(sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMedian(series):\n",
    "    pdTrafficRecentRelativeAuth = series[tyneWearSensorZones[authority]]\n",
    "    \n",
    "    dfMedianPc = pdTrafficRecentRelativeAuth.median(axis=1)\n",
    "    dfMedianPc.index = dfMedianPc.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "    \n",
    "    return dfMedianPc\n",
    "\n",
    "for authority in tyneWearSensorZones.keys():\n",
    "    dfMedianPc = getMedian(pdTrafficRecentRelativePc)\n",
    "    #dfMedianPcPeak = getMedian(pdTrafficRecentRelativePcPeak)\n",
    "    #dfMedianPcInterPeak = getMedian(pdTrafficRecentRelativePcInterPeak)\n",
    "    \n",
    "    pdTrafficRecentRelativeAuth = pdTrafficRecentRelativePc[tyneWearSensorZones[authority]]\n",
    "    \n",
    "    dfMedianPc = pdTrafficRecentRelativeAuth.median(axis=1)\n",
    "    dfMedianPc.index = dfMedianPc.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "    \n",
    "    addAverage(tyneWearAuthorities[authority], dfMedianPc)\n",
    "    addSeries(tyneWearAuthorities[authority], pdTrafficRecentRelativeAuth)\n",
    "    addSeries(tyneWearAuthorities[authority], pdTrafficRecentRelativePcPeak[tyneWearSensorZones[authority]], 'peak')\n",
    "    addSeries(tyneWearAuthorities[authority], pdTrafficRecentRelativePcInterPeak[tyneWearSensorZones[authority]], 'inter-peak')\n",
    "    # dfMedianPc\n",
    "\n",
    "    highlights = {\n",
    "        # Northumberland\n",
    "        'CAJT_NBA189_MF8_RB9.end.northbound': 'A189 Bedlington\\nNorthbound',\n",
    "        'CAJT_NBA189_RB9_MF8.start.southound': 'A189 Bedlington\\nSouthbound',\n",
    "        'CAJT_NBA189_MF8_RB9.start.northbound': 'A189 at A19\\nNorthbound',\n",
    "        'CAJT_NBA189_RB9_MF8.end.southbound': 'A189 at A19\\nSouthbound',\n",
    "        \n",
    "        # Gateshead\n",
    "        'CAJT_GHB1296_ODR3_ODR2.start.northbound': 'Twds QE Hospital\\nfrom South',\n",
    "        'CAJT_GHA167_DR3_NB4.start.southbound': 'Angel of North\\nSouthbound',\n",
    "        'CAJT_GHA1114_CR2_HD3.end.westbound': 'Metrocentre Int\\nWestbound',\n",
    "        'CAJT_GHA695_SG_SB.start.eastbound': 'Stargate Ind Est\\ntwds Gateshead',\n",
    "        'CAJT_GHA167_DR3_DR2.end.northbound': 'Low Fell\\nNorthbound',\n",
    "        \n",
    "        # Newcastle\n",
    "        'CAJT_NCA193_CR3_SRB2.end.westbound': 'Byker Bypass\\nWestbound',\n",
    "        'CAJT_NCA193_SRB2_SR3.end.eastbound': 'Shields Road\\nShopping Eastbound',\n",
    "        'CAJT_NCA695_SWR2_SWR1.end.eastbound': 'Newcastle College\\nScotswood Road',\n",
    "        'CAJT_NCB1307_SR2_SR1.end.westbound': 'Sandyford Road\\nCivic Centre',\n",
    "        'CAJT_NCA189_JDR4_GR.start.southbound': 'Jesmond Dene Rd\\nSouthbound',\n",
    "        \n",
    "        # Sunderland\n",
    "        'CAJT_SLA183_B3_CR2.end.eastbound': 'Sunderland Hosp\\nfrom West',\n",
    "        'CAJT_SLA1290_DL1_NO2.end.westbound': 'Nissan\\nfrom A19',\n",
    "        'CAJT_SLA1018_NR3_NR2.end.southbound': 'Tesco Extra\\nfrom North',\n",
    "        'CAJT_SLA1018_CR3_CK4.start.southbound': 'Ocean Road\\nfrom North',\n",
    "        \n",
    "        # North Tyneside\n",
    "        'CAJT_NTA188_BR5_BR6.end.northbound': 'Quorum BP\\nfrom South',\n",
    "        'CAJT_NTA188_BR6_BR5.start.southbound': 'Quorum BP\\nfrom North',\n",
    "        'CAJT_NTA1058_CR5_BR6.end.easthbound': 'Beach Road\\nEastbound',\n",
    "        'CAJT_NTA193_HS4_CB5.start.eastbound': 'Wallsend\\nEastbound',\n",
    "        'CAJT_NTA193_CB5_HS4.end.westbound': 'Wallsend\\nWestbound',\n",
    "        \n",
    "        # South Tyneside\n",
    "        'CAJT_STA185_TD1_HS2.start.westbound': 'Port of Tyne\\nfrom East',\n",
    "        'CAJT_STA194_AR1A_TD1.start.eastbound': 'Port of Tyne\\nfrom South',\n",
    "        'CAJT_STA1018_GR4_WR5.end.northbound': 'Beach Road\\nNorthbound',\n",
    "        'CAJT_STA1300_LL2_JRR1.end.eastbound': 'South Tyneside\\nHosp Eastbound',\n",
    "        'CAJT_STA184_NR3_AR4.end.eastbound': 'West Boldon\\nEastbound',\n",
    "        \n",
    "        # 'CAJT_NCA695_SWR3_SB.start': 'Scotswood Road\\nReece Group',\n",
    "        #'CAJT_NCA189_SJB2_SJB1.start': 'Gallowgate - St\\nJames Park'\n",
    "    }\n",
    "\n",
    "    # Too crowded :-)\n",
    "    medianSet = {\n",
    "        'Median': dfMedianPc #,\n",
    "        # 'Peak (7-10, 16-19)': dfMedianPcPeak,\n",
    "        # 'Inter-peak (10-16)': dfMedianPcInterPeak \n",
    "    }\n",
    "    plt, fig, ax = traffic.plotTraffic(pdTrafficRecentRelativeAuth, medianSet, highlights)\n",
    "\n",
    "    plt.suptitle(tyneWearAuthorities[authority], fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Traffic volumes relative to baseline of %s to 15 March 2020' % (np.min(pdTrafficTyneWear.index).strftime('%d %B %Y')), fontsize=12)\n",
    "    \n",
    "    totalObservations = '{:,}'.format(int(pdTrafficTyneWear[pdTrafficRecentRelativeAuth.select_dtypes(plottableTypes).columns].sum().sum()))\n",
    "    plt.figtext(\n",
    "        0.05,\n",
    "        -0.07,\n",
    "        'Data is the median across %u monitoring points in %s. Each point is first considered individually relative to baseline data for that day of the week, calculated over the last six months. A total of %s\\n' % (len(pdTrafficRecentRelativeAuth.columns), tyneWearAuthorities[authority], totalObservations) +\n",
    "        'vehicle observations by automatic numberplate recognition cameras were used in the creation of these statistics. Urban Observatory (https://www.urbanobservatory.ac.uk/). Luke Smith <luke.smith@ncl.ac.uk>.',\n",
    "        horizontalalignment='left',\n",
    "        color='#606060',\n",
    "        fontdict={'size': 11}\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hull\n",
    "\n",
    "Statistics in Hull are obtained from inductive loops buried in the road surface, used as part of the SCOOT algorithm that coordinates sets of traffic signals. The underlying data should be at five minute intervals, and represents an average vehicle flow rather than absolute number. It is aggregated to 15 minute intervals first and small gaps of up to 30 minutes are filled with interpolation. The 15 minute interval should be sufficient to smooth out differences caused by traffic light cycles themselves.\n",
    "\n",
    "Data is provided by Hull City Council through their [open data portal](https://opendata.hullcc.gov.uk/). Thanks to Adam Jennison and his colleagues for helping to make this data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTrafficHull = pickle.load(open('../cache/hull-recent-traffic-volumes-pd.pkl', 'rb'))\n",
    "\n",
    "# TODO: Make this reflect the last entry in the frame, not the time now\n",
    "print('Last data obtained %s' \n",
    "    % (np.max(pdTrafficHull.index).strftime('%d %B %Y %H:%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTrafficRecentRelativePc = traffic.makeRelativeToBaseline(pdTrafficHull, capMissingAllHours)\n",
    "pdTrafficRecentRelativePcPeak = traffic.makeRelativeToBaseline(pdTrafficHull, capMissingSubHours * 2, peakHours)\n",
    "pdTrafficRecentRelativePcInterPeak = traffic.makeRelativeToBaseline(pdTrafficHull, capMissingSubHours * 2, interPeakHours)\n",
    "\n",
    "# pdTrafficRecentRelativePc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMedianPc = pdTrafficRecentRelativePc.median(axis=1)\n",
    "dfMedianPc = dfMedianPc[np.isnan(dfMedianPc) == False]\n",
    "dfMedianPc.index = dfMedianPc.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "\n",
    "addAverage('Hull', dfMedianPc)\n",
    "# Too much volatility in this SCOOT data\n",
    "#addSeries('Hull', pdTrafficRecentRelativePc)\n",
    "#addSeries('Hull', pdTrafficRecentRelativePcPeak, 'peak')\n",
    "#addSeries('Hull', pdTrafficRecentRelativePcInterPeak, 'inter-peak')\n",
    "\n",
    "# dfMedianPc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = {\n",
    "    'N42323B': 'Morrisons at\\nHolderness Road',\n",
    "    'N48111F': 'Tesco at\\nGreenwood Ave',\n",
    "    'N11131C': 'Hull Hospital\\nCar Park',\n",
    "    'N41113F': 'Mytongate\\nRoundabout',\n",
    "    'N10111B': 'Walton St\\nWest Park',\n",
    "    'N41243H': 'ASDA\\nMount Pleasant'\n",
    "}\n",
    "\n",
    "plt, fig, ax = traffic.plotTraffic(pdTrafficRecentRelativePc, dfMedianPc, highlights)\n",
    "\n",
    "plt.suptitle('Hull', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Traffic volumes relative to baseline of 7 February to 15 March 2020', fontsize=12)\n",
    "\n",
    "plt.figtext(\n",
    "    0.05,\n",
    "    -0.07,\n",
    "    'Data is the median across %u monitoring points in Hull used in SCOOT traffic signal control. Each point is first considered individually relative to baseline data for that day of the week, calculated 7 Feb - 15 Mar. \\n' % len(pdTrafficRecentRelativePc.columns) +\n",
    "    'Thanks to Adam Jennison at Hull City Council for providing data. Luke Smith <luke.smith@ncl.ac.uk>.',\n",
    "    horizontalalignment='left',\n",
    "    color='#606060',\n",
    "    fontdict={'size': 11}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheffield\n",
    "\n",
    "Statistics in Sheffield are obtained from inductive loops buried in the road surface, used as part of the SCOOT algorithm that coordinates sets of traffic signals. The underlying data should be at five minute intervals, and represents an average vehicle flow rather than absolute number. It is aggregated to 15 minute intervals first and small gaps of up to 30 minutes are filled with interpolation. The 15 minute interval should be sufficient to smooth out differences caused by traffic light cycles themselves.\n",
    "\n",
    "Data is provided by Sheffield City Council and archived by the [Sheffield Urban Flows Observatory](https://urbanflows.ac.uk/), part of the network of UKCRIC Urban Observatories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTrafficSheffield = pickle.load(open('../cache/sheffield-recent-traffic-volumes-pd.pkl', 'rb'))\n",
    "\n",
    "# TODO: Make this reflect the last entry in the frame, not the time now\n",
    "print('Last data obtained %s' \n",
    "    % (np.max(pdTrafficSheffield.index).strftime('%d %B %Y %H:%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdTrafficRecentRelativePc = traffic.makeRelativeToBaseline(pdTrafficSheffield, capMissingAllHours)\n",
    "pdTrafficRecentRelativePcPeak = traffic.makeRelativeToBaseline(pdTrafficSheffield, capMissingSubHours, peakHours)\n",
    "pdTrafficRecentRelativePcInterPeak = traffic.makeRelativeToBaseline(pdTrafficSheffield, capMissingSubHours, interPeakHours)\n",
    "\n",
    "#pdTrafficRecentRelativePc\n",
    "\n",
    "dfMedianPc = pdTrafficRecentRelativePc.median(axis=1)\n",
    "dfMedianPc = dfMedianPc[np.isnan(dfMedianPc) == False]\n",
    "dfMedianPc.index = dfMedianPc.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "\n",
    "addAverage('Sheffield', dfMedianPc)\n",
    "addSeries('Sheffield', pdTrafficRecentRelativePc)\n",
    "addSeries('Sheffield', pdTrafficRecentRelativePcPeak, 'peak')\n",
    "addSeries('Sheffield', pdTrafficRecentRelativePcInterPeak, 'inter-peak')\n",
    "\n",
    "#dfMedianPc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = {\n",
    "    '[SCC]1FJD2': 'Hallamshire\\nHospital',\n",
    "    '[SCC]DET005': 'Netherthorpe Rd\\nBrook Hill',\n",
    "    '[SCC]DET009': 'Parkway\\nEastbound',\n",
    "    '[SCC]DET002': 'Hanover Way\\nA625',\n",
    "    '[SCC]D502_1': 'Chapeltown\\nCowley Ln'\n",
    "}\n",
    "\n",
    "plt, fig, ax = traffic.plotTraffic(pdTrafficRecentRelativePc, dfMedianPc, highlights)\n",
    "\n",
    "plt.suptitle('Sheffield', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Traffic volumes relative to baseline of 1 January to 15 March 2020', fontsize=12)\n",
    "\n",
    "\"\"\"plt.figtext(\n",
    "    0.05,\n",
    "    -0.07,\n",
    "    'Data is the median across %u monitoring points in Hull used in SCOOT traffic signal control. Each point is first considered individually relative to baseline data for that day of the week, calculated 7 Feb - 15 Mar. \\n' % len(pdTrafficRecentRelativePc.columns) +\n",
    "    'Thanks to Adam Jennison at Hull City Council for providing data. Luke Smith <luke.smith@ncl.ac.uk>.',\n",
    "    horizontalalignment='left',\n",
    "    color='#606060',\n",
    "    fontdict={'size': 11}\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average across all authorities\n",
    "\n",
    "These plots includes a median taken from all of the individual monitoring points across all of the authorities above. When considering the median within an authority however, the level of monitoring varies substantially, so be aware that the median for areas such as Northumberland will be more sensitive to changes at a small number of locations.\n",
    "\n",
    "The availability of historic data varies between authorities. A long baseline has been used where possible to calculate the percentage changes, but this will vary between a few weeks (e.g. Hull) and more than six months (e.g. Newcastle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMedianAll = dfAllSeries['all'].median(axis=1)\n",
    "dfMedianPeak = dfAllSeries['peak'].median(axis=1)\n",
    "dfMedianInterPeak = dfAllSeries['inter-peak'].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMedianAll.index = dfMedianAll.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "dfMedianPeak.index = dfMedianPeak.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "dfMedianInterPeak.index = dfMedianInterPeak.index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))\n",
    "\n",
    "dfMedianPeak = dfMedianPeak.reindex(dfMedianAll.index)\n",
    "dfMedianInterPeak = dfMedianInterPeak.reindex(dfMedianAll.index)\n",
    "\n",
    "dfAllSeries['all'].index = dfAllSeries['all'].index.map(lambda d: datetime.datetime.combine(d, datetime.time.min).replace(tzinfo=tzLocal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, fig, ax = traffic.plotTraffic(\n",
    "    dfPlaceAverages, # dfAllSeries['all'].join(dfPlaceAverages),\n",
    "    {\n",
    "        'Median': dfMedianAll,\n",
    "        'Peak (7-10, 16-19)': dfMedianPeak,\n",
    "        'Inter-peak (10-16)': dfMedianInterPeak\n",
    "    },\n",
    "    { p: p for p in dfPlaceAverages.columns },\n",
    "    True,\n",
    "    normalLineAlpha=0.2\n",
    ")\n",
    "\n",
    "percentilesToPlot = [0.1, 0.25]\n",
    "for i, pc in enumerate(percentilesToPlot):\n",
    "    dfLower = dfAllSeries['inter-peak'].quantile(pc, axis=1)\n",
    "    dfUpper = dfAllSeries['inter-peak'].quantile(1.0 - pc, axis=1)\n",
    "\n",
    "    percentileLegend = ax.fill_between(\n",
    "        dfLower.index,\n",
    "        dfLower,\n",
    "        dfUpper,\n",
    "        color='#233067',\n",
    "        linewidth=0,\n",
    "        #edgecolor='red',\n",
    "        alpha=0.1 if i == 0 else 0.15\n",
    "    )\n",
    "    \n",
    "plt.suptitle('All authorities (Tyne and Wear, Hull and Sheffield)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Traffic volumes relative to baselines prior to mandatory social distancing measures', fontsize=12)\n",
    "\n",
    "plt.figlegend(\n",
    "    [percentileLegend],\n",
    "    ['Inter-peak percentiles at ' + ', '.join(map(lambda p: str(round(p * 100)), percentilesToPlot)) + '%'],\n",
    "    loc='upper right',\n",
    "    ncol=1,\n",
    "    labelspacing=0,\n",
    "    handletextpad=0.4,\n",
    "    columnspacing=0.4\n",
    ")\n",
    "\n",
    "plt.figtext(\n",
    "    0.05,\n",
    "    -0.07,\n",
    "    'Data is the median across %u monitoring points across Tyne and Wear, Hull, and Sheffield. Each point is first considered individually relative to baseline data for that day of the week, using varying dates depending on\\n' % len(dfAllSeries['all'].columns) +\n",
    "    'data availability. A mixture of SCOOT and ANPR data is used. Luke Smith <luke.smith@ncl.ac.uk>. Peak and inter-peak points are only provided for weekdays. Bank holidays and weekends are shaded.',\n",
    "    horizontalalignment='left',\n",
    "    color='#606060',\n",
    "    fontdict={'size': 11}\n",
    ")\n",
    "\n",
    "#plt.savefig('../output/traffic-all-authorities.jpg', format='jpg', dpi=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary = dfPlaceAverages.join(dfMedianAll.to_frame(name='All authorities'))\n",
    "dfSummary = dfSummary[dfSummary.index < dateToday]\n",
    "dfSummary.to_pickle('../cache/all-traffic-relative.pkl')\n",
    "dfSummary.to_csv('../output/all-traffic-relative.csv')\n",
    "dfSummary.index = dfSummary.index.map(lambda d: d.strftime('%d %B (%A)'))\n",
    "\n",
    "formattersSummary = {\n",
    "    authority: '{:,.1f}%' for authority in dfSummary.columns\n",
    "}\n",
    "dfSummaryStyler = dfSummary.style \\\n",
    "    .format(formattersSummary) \\\n",
    "    .set_caption('All traffic data relative to baseline') \\\n",
    "    .set_table_styles(\n",
    "        [dict(selector=\"th\",props=[('text-align', 'center'), ('word-wrap', 'break-word')]),\n",
    "         dict(selector=\"caption\", props=[('font-weight', 'bold'), ('font-size', '120%')]),\n",
    "         dict(selector=\"tr th:nth-child(1)\", props=[('width', '140px'), ('max-width', '140px'), ('text-align', 'left')]),\n",
    "         dict(selector=\"tr td\", props=[('width', '75px')])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dfSummaryStyler.bar(color='#FFA07A50', vmin=0, vmax=100.0)\n",
    "dfSummaryStyler.apply(lambda data: ['border-top: 1px dashed black' if ('Saturday' in data.name) else '' for v in data], axis=1)\n",
    "dfSummaryStyler.apply(lambda data: ['border-bottom: 1px dashed black' if  ('Sunday' in data.name) else '' for v in data], axis=1)\n",
    "\n",
    "dfSummaryStyler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
