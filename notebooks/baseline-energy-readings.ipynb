{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts energy data from across campus for 2017-2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import relativedelta\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "## The code threw up some SettingWithCopyWarnings that I will fix at somepoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "secrets = json.load(open('../secrets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers for API calls\n",
    "headers = {\n",
    "    'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "    'Accept-Language': 'en-GB,en;q=0.5',\n",
    "    'Content-Type': 'application/json; charset=utf-8',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'Origin': 'https://metering.dev.urbanobservatory.ac.uk',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://metering.dev.urbanobservatory.ac.uk/utilities/currentmetervalues.aspx',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'TE': 'Trailers',\n",
    "}\n",
    "\n",
    "# Define authorisation credentials. \n",
    "# NOTE! These are for the UO proxy of the metering.ncl.ac.uk website. \n",
    "# They will not work for the main website, and other authorisation may be required.\n",
    "auth = (\n",
    "    secrets['metering']['username'],\n",
    "    secrets['metering']['password']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call metadata\n",
    "url = 'https://metering.dev.urbanobservatory.ac.uk/utilities/currentmetervalues.aspx/GetMeters'\n",
    "\n",
    "r = requests.post(url=url, headers=headers,auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract JSON data, import to dataframe. \n",
    "sensorData = r.json()\n",
    "sensorData = sensorData[\"d\"]\n",
    "sensorData = json.loads(sensorData)\n",
    "\n",
    "cols= list(sensorData[0].keys())\n",
    "sensorDF = pd.DataFrame(columns = cols)\n",
    "\n",
    "for s in range(1,len(sensorData)):\n",
    "    row = sensorData[s]\n",
    "    sensorDF = sensorDF.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded list of selected sensors - to be updated for more dynamic selection of locations\n",
    "sensorID = ['CLZ_E_Tx1',    # Castle Leazes \n",
    "           'DEV_E_Main',   # Devonshire \n",
    "           'HAN_E_Main',   # Great North Museum \n",
    "           'REF_E_Main',   # Kings Road Centre\n",
    "           'PCY_E_Main',   # Percy Building\n",
    "           'CSH_E_Main',   # Sports Center \n",
    "           'UNS_E_Main',   # Students Union\n",
    "           'W22_E_Main',   # Windsor Terrace (Law)\n",
    "           'WOL_E_Main']   # Wolfson Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call data from METERology\n",
    "def callData(location, startDate, endDate, utility):\n",
    "    print(datetime.now().strftime('%H:%M:%S'))\n",
    "    \n",
    "    # Determine number months in date range.\n",
    "    # If less than 10, run API call, if greater than 10, run API calls\n",
    "    monthList = pd.date_range(startDate,endDate,freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "    monthNum = len(monthList)\n",
    "    \n",
    "    paramList = list()\n",
    "    if monthNum <=15:\n",
    "        dataSplit = False\n",
    "        for sid in location:\n",
    "            params = {\"meterID\":sid,\n",
    "                    \"startDateISO\":startDate,\n",
    "                    \"endDateISO\":endDate}\n",
    "            params = str(params)\n",
    "            paramList.append(params)\n",
    "    else:\n",
    "        dataSplit = True\n",
    "        numChunks = int(len(monthList)/15) + (len(monthList)%15 > 0)\n",
    "        for sid in location:\n",
    "            iter = 1\n",
    "            sd = 0\n",
    "            ed = 14\n",
    "            while iter <= numChunks:\n",
    "                start = monthList[sd]+'-01'\n",
    "                if iter == numChunks:\n",
    "                    end = monthList[-1] + '-' + str(calendar.monthrange(int(monthList[-1][:4]), int(monthList[-1][-2:]))[1])\n",
    "                else:\n",
    "                    end = monthList[ed] + '-' + str(calendar.monthrange(int(monthList[ed][:4]), int(monthList[ed][-2:]))[1])\n",
    "                params = {\"meterID\":sid,\n",
    "                        \"startDateISO\":start,\n",
    "                        \"endDateISO\":end}\n",
    "                params = str(params)\n",
    "                paramList.append(params)\n",
    "                sd = sd + 15\n",
    "                ed = ed + 15\n",
    "                iter = iter+1\n",
    "        \n",
    "    # Update params for request session\n",
    "    with requests.Session() as s:\n",
    "        s.auth = auth\n",
    "        s.headers.update({\n",
    "            'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "            'Accept-Language': 'en-GB,en;q=0.5',\n",
    "            'Content-Type': 'application/json; charset=utf-8',\n",
    "            'X-Requested-With': 'XMLHttpRequest',\n",
    "            'Origin': 'https://metering.dev.urbanobservatory.ac.uk',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://metering.dev.urbanobservatory.ac.uk/utilities/historicalhalfhourreadings.aspx',\n",
    "            'Pragma': 'no-cache',\n",
    "            'Cache-Control': 'no-cache'\n",
    "        })\n",
    "\n",
    "        url = \"https://metering.dev.urbanobservatory.ac.uk/utilities/historicalhalfhourreadings.aspx/GetReadings\"\n",
    "        \n",
    "        resultsDict = dict()\n",
    "        \n",
    "        current = 1\n",
    "        total = len(paramList)\n",
    "        \n",
    "        for par in paramList:\n",
    "            sid = ast.literal_eval(par)\n",
    "            sid = sid.get('meterID')\n",
    "            \n",
    "            if dataSplit == True:\n",
    "                sid = sid + '---Iter' + str(current)\n",
    "            \n",
    "            print(sid,\":\",\"(\",current,\"/\",total,\")\")\n",
    "        \n",
    "            r = s.post(url=url,data=par)\n",
    "            \n",
    "            data = r.json()\n",
    "            data = data[\"d\"]\n",
    "            data = json.loads(data)\n",
    "            \n",
    "            resultsDict.update({sid : data})\n",
    "        \n",
    "            current = current + 1\n",
    "            \n",
    "    print(datetime.now().strftime('%H:%M:%S'))\n",
    "    return resultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters, call function using hardcoded sensor list\n",
    "startDate = \"2017-01-01 00:00:00\" # Please use YYYY-MM-DD format, or type default. \n",
    "endDate = \"2020-02-29 23:59:59\" # Please use YYYY-MM-DD format, or type default. \n",
    "utility = \"All\" # Options are Electricity, Gas, Heat or Water. Type \"All\" to download all datasets.\n",
    "\n",
    "resultsDict = callData(sensorID, startDate, endDate, utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat Data into DataFrame\n",
    "reformatDF = pd.DataFrame()\n",
    "\n",
    "total = len(resultsDict)\n",
    "current = 1\n",
    "\n",
    "for sid in resultsDict:\n",
    "    print(sid,\":\",\"(\",current,\"/\",total,\")\")\n",
    "    print(datetime.now().strftime('%H:%M:%S'))\n",
    "    data = resultsDict.get(sid)\n",
    "    tempDF = pd.DataFrame()\n",
    "    tempDF = pd.DataFrame(data)\n",
    "    idString = sid.split(\"---\")\n",
    "    tempDF[\"id\"] = idString[0]\n",
    "    reformatDF = reformatDF.append(tempDF, ignore_index = True)\n",
    "    tempDF = None\n",
    "    current = current +1 \n",
    "    \n",
    "reformatDF = reformatDF.dropna(subset=['reading'])\n",
    "reformatDF.loc[:,\"DateTime\"] = reformatDF['date'] + ' ' + reformatDF['time']\n",
    "reformatDF.loc[:,\"DateTime\"] = pd.to_datetime(reformatDF['DateTime'],format='%d/%m/%Y %H:%M')\n",
    "reformatDF.drop(columns=['date','time'], axis=1, inplace=True)\n",
    "\n",
    "# Create List of DateTimes of Expected Readings (Every 30 mins)\n",
    "def datetime_range(start, end, delta):\n",
    "    current = start\n",
    "    while current < end:\n",
    "        yield current\n",
    "        current += delta\n",
    "        \n",
    "first = \"01/01/2017 00:00\" \n",
    "last = \"29/02/2020 23:45\" \n",
    "        \n",
    "expectedDates = [dt.strftime('%d/%m/%Y %H:%M') for dt in \n",
    "       datetime_range(datetime.strptime(first, '%d/%m/%Y %H:%M'), datetime.strptime(last, '%d/%m/%Y %H:%M'), \n",
    "       timedelta(minutes=30))]\n",
    "\n",
    "# Make DataFrame user-friendly\n",
    "resultsDF = pd.DataFrame(index=expectedDates)\n",
    "\n",
    "for sid in sensorID:\n",
    "    tempDF = reformatDF[reformatDF['id']==sid]\n",
    "    tempDF.index = tempDF[\"DateTime\"]\n",
    "    tempDF = tempDF.drop(columns=['id','DateTime'], axis=1)\n",
    "    \n",
    "    resultsDF = resultsDF.merge(tempDF, how='outer',left_index=True, right_index=True)\n",
    "    resultsDF.columns = [*resultsDF.columns[:-1], sid]\n",
    "    \n",
    "resultsDF = resultsDF.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(sensorDF, '../cache/energy-metadata.pkl')\n",
    "pd.to_pickle(resultsDF, '../cache/energy-baseline.pkl')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
